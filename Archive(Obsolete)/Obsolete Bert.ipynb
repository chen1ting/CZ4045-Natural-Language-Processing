{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obsolete Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8a1342f9-6611-4c23-88dc-ec6fa39d2efb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# don't consider uncleaned text for now (too much noise)\n",
    "preprocessings = ['cleaned_stemmed_text', 'cleaned_lemmatized_text', 'cleaned_text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "08191bcf-4411-4b32-85c9-401148383c89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sub_df = df[df['Subjectivity'].notna()].copy()\n",
    "sub_df = sub_df.dropna(subset=preprocessings)\n",
    "sub_df['Subjectivity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "de8b949c-8952-4d61-a20e-1b885144efcf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can see that here the class is highly unbalanced with too many biased content. For better output, we need to balance the dataset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1c9288fc-5ee3-47c0-a6cd-4695f771b2a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Random oversampling involves randomly selecting examples from the minority class, with replacement, and adding them to the training dataset.\n",
    "sampler = RandomUnderSampler(random_state=seed)\n",
    "X_sub, Y_sub = sampler.fit_resample(sub_df[preprocessings], sub_df['Subjectivity'])\n",
    "Y_sub.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "98983615-724c-41bf-a5f3-bfef49addd17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# do the same for 'Polarity'\n",
    "polar_df = df[df['Polarity'].notna()].copy()\n",
    "polar_df = polar_df.dropna(subset=preprocessings)\n",
    "polar_df['Polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7b382b93-67e1-4955-a0cf-a74b5e51ad53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_polar, Y_polar = sampler.fit_resample(polar_df[preprocessings], polar_df['Polarity'])\n",
    "Y_polar.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e99b9fff274f929ad0d6a960724b716a6efa99eda1fd72f9472e67fbbaca8a8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
