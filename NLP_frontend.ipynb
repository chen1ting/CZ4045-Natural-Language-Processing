{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio\n",
    "# !pip3 install twint\n",
    "# !pip install aiohttp==3.7.0\n",
    "# !pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4a1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(game_title:str, number_of_tweets:int):\n",
    "    try:\n",
    "        number_of_tweets = int(number_of_tweets)\n",
    "    except:\n",
    "        return None\n",
    "    timestr = time.strftime(\"%Y%m%d\")\n",
    "    #configuration\n",
    "    c = twint.Config()        \n",
    "    c.Lang = \"en\"        # Language\n",
    "    c.Store_csv = True\n",
    "    c.Limit = number_of_tweets\n",
    "    c.Search = game_title  # key words to look for.\n",
    "    c.Output = f\"{timestr}_{game_title}.csv\"\n",
    "    twint.run.Search(c)\n",
    "    return pd.read_csv(f\"{timestr}_{game_title}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959503dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function for analyzing overall sentiment\n",
    "def analyze_sentiment(df:pd.DataFrame):\n",
    "    if sentiment < 0.25:\n",
    "        overall_sentiment = \"very negative\"\n",
    "    elif sentiment < 0.5:\n",
    "        overall_sentiment = \"negative\"\n",
    "    elif sentiment < 0.75:\n",
    "        overall_sentiment = \"positive\"\n",
    "    else:\n",
    "        overall_sentiment = \"very positive\"\n",
    "    return overall_sentiment\n",
    "\n",
    "def nlp(game_title, number_of_tweets, activate_scrape):\n",
    "    \n",
    "    df = scrape(game_title, number_of_tweets)\n",
    "    \"\"\"\n",
    "    #insert function to scrape twitter for game title here\n",
    "    \n",
    "    #insert preprocessing function here\n",
    "    processed_dataset = preprocess(dataset)\n",
    "    \n",
    "    #run through predictor\n",
    "    predicted_dataset = predict(processed_dataset)\n",
    "    \n",
    "    #Reviewing overall sentiment\n",
    "    sentiment = 0.22\n",
    "    \"\"\"\n",
    "    \n",
    "    #if scrape checkbox is marked\n",
    "    if activate_scrape:\n",
    "        overall_sentiment = analyze_sentiment(sentiment)\n",
    "\n",
    "        return {'analysis' : \"overall sentiment for \" + game_title + \" is \" + overall_sentiment,\n",
    "                'scraped_tweets' : \"testing\\n\",\"testing\"}\n",
    "    else:\n",
    "        overall_sentiment = analyze_sentiment(sentiment)\n",
    "\n",
    "        return {'analysis' : \"overall sentiment for \" + game_title + \" is \" + overall_sentiment}\n",
    "#iface = gr.Interface(fn=nlp, inputs=[\"text\", gr.Slider(0,1.00)], outputs=\"text\")\n",
    "#iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6355ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            game_title = gr.Textbox(label = \"Game Title\")\n",
    "            number_of_tweets = gr.Slider(0,1000, label = \"Amount of tweets to scrape\")\n",
    "            activate_scrape = gr.Checkbox(label = \"Show scraped data?\")\n",
    "            submit_button = gr.Button(\"Submit\")\n",
    "        with gr.Column(scale=4):\n",
    "            analysis = gr.Textbox(label = \"Sentiment\")\n",
    "            scraped_tweets = gr.Textbox(label = \"Scraped Data\")\n",
    "    \n",
    "    submit_button.click(nlp, inputs=[game_title,number_of_tweets,activate_scrape], outputs=[analysis, scraped_tweets])\n",
    "    \n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f783431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e99b9fff274f929ad0d6a960724b716a6efa99eda1fd72f9472e67fbbaca8a8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
